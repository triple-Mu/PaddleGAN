total_iters: 100000
output_dir: training

model:
  name: NAFNetModel
  generator:
    name: ReconstructiveSubNetwork
    in_channels: 3
    out_channels: 3
    base_width: 16
  psnr_criterion:
    name: CharbonnierLoss # L1Loss CharbonnierLoss PSNRLoss SSIM

dataset:
  train:
    name: NAFNetTrain
    rgb_dir: data/SIDD/train
    is_npy: true
    # TODO fix out of memory for val while training
    num_workers: 8
    batch_size: 32 # 8GPU
    img_options:
      patch_size: 1024
  test:
    name: NAFNetVal
    rgb_dir: data/SIDD/val
    is_npy: true
    # TODO fix out of memory for val while training
    num_workers: 4
    batch_size: 32
    img_options:
      patch_size: 1024

export_model:
  - {name: 'generator', inputs_num: 1}

lr_scheduler:
  name: CosineAnnealingRestartLR
  learning_rate: 0.001
  periods: [100000]
  restart_weights: [1]
  eta_min: !!float 8e-7

validate:
  interval: 200
  save_img: false

  metrics:
    psnr: # metric name, can be arbitrary
      name: PSNR
      crop_border: 4
      test_y_channel: True
    ssim:
      name: SSIM
      crop_border: 4
      test_y_channel: True

optimizer:
  name: AdamW
  # add parameters of net_name to optim
  # name should in self.nets
  net_names:
    - generator
  weight_decay: 0.0
  beta1: 0.9
  beta2: 0.9
  epsilon: 1e-8

log_config:
  interval: 10
  visiual_interval: 50000

snapshot_config:
  interval: 200
