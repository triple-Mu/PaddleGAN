total_iters: 100000
output_dir: work_dirs/nafnet_n_plus_step2

model:
  name: NAFNetModel
  generator:
    name: NAFNet
    img_channel: 3
    width: 16
    enc_blk_nums: [2, 2, 1, 1]
    middle_blk_num: 1
    dec_blk_nums: [2, 2, 2, 2]
  psnr_criterion:
    name: PSNRLoss # L1Loss CharbonnierLoss PSNRLoss SSIM

dataset:
  train:
    name: NAFNetTrain
    rgb_dir: data/SIDD/train
    # TODO fix out of memory for val while training
    num_workers: 8
    batch_size: 6 # 8GPU
    img_options:
      patch_size: 1024
  test:
    name: NAFNetVal
    rgb_dir: data/SIDD/val
    # TODO fix out of memory for val while training
    num_workers: 4
    batch_size: 1
    img_options:
      patch_size: 1024

export_model:
  - {name: 'generator', inputs_num: 1}

lr_scheduler:
  name: CosineAnnealingRestartLR
  learning_rate: 0.0001
  periods: [100000]
  restart_weights: [1]
  eta_min: !!float 8e-7

validate:
  interval: 500
  save_img: false

  metrics:
    psnr: # metric name, can be arbitrary
      name: PSNR
      crop_border: 4
      test_y_channel: True
    ssim:
      name: SSIM
      crop_border: 4
      test_y_channel: True

optimizer:
  name: AdamW
  # add parameters of net_name to optim
  # name should in self.nets
  net_names:
    - generator
  weight_decay: 0.0
  beta1: 0.9
  beta2: 0.9
  epsilon: 1e-8

log_config:
  interval: 100
  visiual_interval: 10000

snapshot_config:
  interval: 200
  save_best:
    path: training/records
